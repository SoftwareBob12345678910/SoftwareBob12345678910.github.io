---
Title: DBS101 Unit 6
categories : [DBS101, Unit6]
tags : [DBS101]
---


# Database Systems Learning Portfolio: Query Processing and Optimization


## Introduction

In today's blog post, I'm going to reflect on one of the most fascinating topics we've covered in our Database Systems course (DBS101) - Query Processing and Optimization. This topic stands at the intersection of theoretical computer science and practical database implementation, and honestly, it has given me a whole new appreciation for what happens behind the scenes when I run even a simple SQL query.

## What is Query Processing?

Query processing refers to the range of activities involved in extracting data from a database. It includes translating high-level queries (like those written in SQL) into expressions that can be used at the physical level of the file system, optimizing these queries, and then actually evaluating them to retrieve results.

Before diving into this topic, I had always taken for granted how quickly databases respond to our queries. I never stopped to consider the complexity involved in translating my SQL statement into something the database can efficiently execute. Now I understand that there's an entire pipeline of processes happening in milliseconds!

## Query Processing Steps

There are three main steps involved in query processing:

1. **Parsing and Translation**: 
   - The SQL query is checked for syntax errors
   - Relations referenced in the query are validated
   - The query is parsed into a parse tree
   - It's translated into a relational algebra expression
   - Any views are replaced with their definitions

2. **Optimization**:
   - The database generates multiple possible execution plans
   - It estimates the cost of each plan based on statistics and cost models
   - It selects the plan with the lowest estimated cost

3. **Evaluation**:
   - The chosen query execution plan is executed
   - Results are returned to the user

## Query Execution Plans

One concept that particularly interested me was that of query execution plans. I learned that a query can be executed in multiple ways, and the database system needs to choose the most efficient method.

For example, consider a simple query:
```sql
SELECT * FROM students WHERE gpa > 3.5
```

This could be executed by:
- Scanning the entire students table and filtering records with GPA > 3.5
- Using an index on the GPA column to quickly locate qualifying records

The database optimizer must choose between these approaches based on factors like:
- Whether an index exists on the GPA column
- What proportion of records have GPA > 3.5
- The total number of records in the table

## Measuring Query Cost

Another enlightening aspect was understanding how database systems measure and compare the cost of different execution plans. While traditionally, the focus was primarily on disk I/O costs, modern systems also consider:

- **Disk I/O Cost**: The number of blocks transferred and random I/O accesses
- **CPU Cost**: The computational effort required to process the query
- **Memory Usage**: The amount of buffer space needed

For disk-based systems, the cost formula is often represented as:
```
Cost = b * tT + S * tS
```
Where:
- b = number of blocks transferred
- tT = average block transfer time
- S = number of random I/O accesses
- tS = average block access time (seek time + rotational latency)

The lecture provided interesting typical values for these parameters:
- For magnetic disks: tS = 4ms, tT = 0.1ms
- For SSDs: tS = 90μs, tT = 10μs

This helps explain why SSDs can provide such significant performance improvements for database workloads!

## Pipelining vs. Materialization

Two approaches to query execution that were discussed are pipelining and materialization:

- **Materialization**: Each operation is executed completely before the next operation starts. Intermediate results are stored in temporary relations.

- **Pipelining**: Results are passed directly from one operation to the next without creating temporary relations. This can significantly reduce execution time and I/O costs.

I found the pipeline approach particularly elegant. It's like an assembly line for data processing, where each operator in the query plan continuously processes and passes tuples to the next operator.

## What is Query Optimization?

Building on our understanding of query processing, I want to explore query optimization in more detail based on our recent Lesson 16. Query optimization is the process of selecting the most efficient query-evaluation plan from among the many strategies possible for processing a given query, especially if the query is complex.

## Transformation of Relational Expressions

Relational algebra expressions can be transformed into equivalent expressions with different evaluation costs. Two expressions are equivalent if they generate the same set of tuples on every legal database instance.

## Equivalence Rules

Equivalence rules allow replacing an expression with an equivalent one. Query optimizers use these rules to transform expressions into more efficient forms.

In these rules:
- σ (Sigma): Selection operator
- ⋈ (Theta Join): Join operator
- θ1, θ2: Predicate conditions used for selection or joining
- E1, E2: Relations or tables involved in the operations

Some important equivalence rules include:

- Conjunctive selection can be deconstructed:
  ```
  σθ1∧θ2(E) ≡ σθ1(σθ2(E))
  ```

- Selection operations are commutative:
  ```
  σθ1(σθ2(E)) ≡ σθ2(σθ1(E))
  ```

- Theta joins are commutative:
  ```
  E1 ⋈θ E2 ≡ E2 ⋈θ E1
  ```

- Natural joins are associative:
  ```
  (E1 ⋈ E2) ⋈ E3 ≡ E1 ⋈ (E2 ⋈ E3)
  ```

- Selection distributes over join:
  ```
  σθ1(E1 ⋈θ E2) ≡ (σθ1(E1)) ⋈θ E2 (if θ1 only involves E1)
  ```

## Example Transformation

Here's an example of how a query can be transformed:

Original:
```
Πname,title(σdept_name="Music" ∧ year=2017(instructor ⋈ (teaches ⋈ Πcourse_id,title(course))))
```

Transformed:
```
Πname,title((σdept_name="Music"(instructor)) ⋈ σyear=2017(teaches) ⋈ Πcourse_id,title(course))
```

## Join Ordering

Join ordering is critically important for reducing intermediate result sizes. Since natural joins are associative and commutative, we can reorder them to improve efficiency.

For example:
```
(instructor ⋈ teaches) ⋈ Πcourse_id,title(course)
```

is typically more efficient than:

```
(instructor ⋈ Πcourse_id,title(course)) ⋈ teaches
```

The optimization depends on which join order produces smaller intermediate results.

Consider a query involving customers, orders, and line items:

Which join order is more efficient?
1. First filtering customers, then joining with orders, and finally with line items
2. Starting with line items joined to orders, then joining with customers

The first join order is very efficient because most customers are filtered early, creating a tiny intermediate relation. The second join order produces a large intermediate relation because we map every line item to an order only to discard most of the produced tuples in the second join.

## Enumeration of Equivalent Expressions

Query optimizers systematically generate equivalent expressions using rules, compute the cost of each expression based on statistics, and choose the lowest cost equivalent expression.

## Estimating Statistics

The cost of an operation depends on statistics like input size. Query optimizers estimate statistics bottom-up for each operation. While these estimates aren't fully accurate, they provide a reasonable approximation for making optimization decisions.

## Choice of Evaluation Plans

Generating expressions is part of the query optimization process. An evaluation plan defines exactly:
- What algorithm should be used for each operation (e.g., nested loop join, hash join)
- How the execution of operations should be coordinated

We can estimate the cost of a plan using statistics and algorithm cost estimates.

For example, consider the query: 
```sql
SELECT * FROM R, S WHERE R.A = S.B
```

Possible plans include:
1. Nested Loop Join: Scan R, for each tuple use index on S.B
2. Sort-Merge Join: Sort R on A, Sort S on B, merge

## Cost-Based Optimization

Cost-based optimization explores the space of all equivalent query evaluation plans, uses equivalence rules to generate alternative plans, and chooses the plan with the least estimated cost. It covers two main aspects:
- Join order selection
- Choosing join algorithms (nested loop, hash join, etc.)

## Join Order Optimization

Join order optimization uses a dynamic programming algorithm to find the optimal join order for a given set of relations. It considers interesting sort orders for interim results, as sorted results may be useful for later operations. The time complexity is O(3^n) where n is the number of relations.

## General Cost-Based Optimization

General cost-based optimization uses equivalence rules to explore alternatives with various operations (outer joins, aggregations, nested queries, etc.). It generates all possible equivalent evaluation plans and uses efficient techniques:
- Avoids duplicating shared subexpressions
- Detects duplicate derivations
- Uses memoization (dynamic programming)
- Prunes more expensive plans

## Optimization Heuristics

Optimization heuristics are used to reduce the cost of optimization itself. Examples include:
- Perform selections early to reduce data size
- Perform projections early after selections
- Use left-deep join trees (easy for pipelining)
- Plan caching: Reuse plans for repeated queries with different constants

## Nested Subqueries

Correlated evaluation (invoking subquery repeatedly) is very inefficient. Query optimizers try to decorrelate by rewriting nested subqueries using joins, semijoins, or anti-joins. Complex cases involving aggregates or scalar subqueries may not be decorrelated, so it's best to avoid complex nested subqueries if possible.

Example:
```sql
SELECT name FROM instructor
WHERE exists (SELECT * FROM teaches WHERE instructor.ID = teaches.ID AND teaches.year = 2019)
```

Can be rewritten using semi join as:
```
Πname(instructor ⋉instructor.ID=teaches.ID ∧ teaches.year=2019 teaches)
```

## Optimization Techniques for Common Operations

The course also covered optimization techniques for common database operations:

### Selection Operation
- Using indices for equality selection
- Composite indices for conjunctive selection
- Bitmap indices for complex selections

### Join Operations
- Nested-loop join
- Block nested-loop join
- Indexed nested-loop join
- Merge join
- Hash join

### Other Operations
- Sorting using external sort-merge
- Duplicate elimination
- Aggregation
- Set operations

## In-Memory Query Processing

With the decreasing cost of memory, more databases are being designed to work primarily in memory. This changes the optimization focus from minimizing disk I/O to optimizing CPU cache utilization.

Techniques for in-memory processing include:
- Cache-conscious algorithms
- Optimized data layout
- Query compilation (translating queries directly into machine code)

## Personal Reflections

### What I Found Most Interesting

The part I found most fascinating was understanding how the database optimizer makes decisions. It's like a chess game where the system needs to think several moves ahead, evaluating different strategies to find the most efficient path to the result. The equivalence rules and transformation principles were particularly enlightening.

### Challenges I Encountered

The mathematical cost models were initially challenging for me to grasp. Understanding how to calculate the exact cost of different query operations required working through several examples. The complexity of the join ordering algorithms with their O(3^n) complexity was also challenging to fully comprehend.

### Practical Applications

This knowledge has practical applications in my other coursework. Now when I'm writing queries for my projects, I think more carefully about:
- The indices I should create
- How to structure complex queries for better performance
- Understanding query execution plans to diagnose performance issues
- Avoiding correlated subqueries when possible
- Considering join order in multi-table queries

### Future Learning Goals

Based on what I've learned, I want to explore:
1. Execution plan visualization tools in specific database systems
2. More advanced query optimization techniques
3. How query processing differs in distributed database systems
4. Statistics collection and maintenance in commercial database systems
5. Query optimization in NoSQL databases

## Conclusion

Query processing and optimization are at the heart of database performance. Understanding these topics has given me a much deeper appreciation for the complexity behind every SQL query I write. It's not just about getting the correct results, but about getting them efficiently.

As databases continue to evolve with new storage technologies and processing approaches, the principles of query processing and optimization will remain fundamental. I'm excited to see how these concepts will apply to emerging database architectures and to put this knowledge into practice in my future work.